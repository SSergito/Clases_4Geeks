{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo secuencial (capas apiladas linealmente)\n",
    "model = Sequential([\n",
    "    # Primera capa convolucional:\n",
    "    # - 32 filtros de 3x3 píxeles\n",
    "    # - Activación ReLU (Rectified Linear Unit) para introducir no linealidad\n",
    "    # - Input shape: 100x100 píxeles con 3 canales (RGB)\n",
    "    # - Padding: 'valid' por defecto (sin relleno)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    \n",
    "    # Batch Normalization:\n",
    "    # - Normaliza las activaciones de la capa anterior\n",
    "    # - Estabiliza y acelera el entrenamiento\n",
    "    # - Reduce la dependencia de la inicialización de pesos\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Max Pooling:\n",
    "    # - Reducción dimensional con ventana de 2x2\n",
    "    # - Toma el valor máximo en cada región\n",
    "    # - Reduce el tamaño espacial a la mitad (50x50)\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Dropout (25%):\n",
    "    # - Apaga aleatoriamente el 25% de las neuronas durante el entrenamiento\n",
    "    # - Previene overfitting al evitar co-adaptaciones de neuronas\n",
    "    Dropout(0.25), \n",
    "    \n",
    "    # Segunda capa convolucional:\n",
    "    # - 64 filtros de 3x3\n",
    "    # - Profundiza en características más complejas\n",
    "    Conv2D(64, (3, 3), activation='relu'), \n",
    "    \n",
    "    # Batch Normalization:\n",
    "    # - Normalización para la segunda capa convolucional\n",
    "    BatchNormalization(), \n",
    "    \n",
    "    # Max Pooling:\n",
    "    # - Otra reducción dimensional (25x25)\n",
    "    MaxPooling2D(pool_size=(2, 2)), \n",
    "    \n",
    "    # Dropout (25%):\n",
    "    # - Regularización consistente con la primera capa\n",
    "    Dropout(0.25), \n",
    "    \n",
    "    # Tercera capa convolucional:\n",
    "    # - 128 filtros de 3x3\n",
    "    # - Captura patrones de alto nivel\n",
    "    Conv2D(128, (3, 3), activation='relu'), \n",
    "    \n",
    "    # Batch Normalization:\n",
    "    BatchNormalization(), \n",
    "    \n",
    "    # Max Pooling final:\n",
    "    # - Última reducción (12x12 considerando padding)\n",
    "    MaxPooling2D(pool_size=(2, 2)), \n",
    "    \n",
    "    # Dropout final convolucional (25%):\n",
    "    Dropout(0.25), \n",
    "    \n",
    "    # Aplanamiento:\n",
    "    # - Convierte el tensor 3D a 1D para la capa densa\n",
    "    Flatten(), \n",
    "    \n",
    "    # Capa densa completamente conectada:\n",
    "    # - 512 neuronas\n",
    "    # - Activación ReLU\n",
    "    # - Combina características aprendidas para la clasificación\n",
    "    Dense(512, activation='relu'), \n",
    "    \n",
    "    # Batch Normalization final:\n",
    "    BatchNormalization(), \n",
    "    \n",
    "    # Dropout alto (50%):\n",
    "    # - Mayor regularización en capas densas donde el overfitting es más probable\n",
    "    Dropout(0.5), \n",
    "    \n",
    "    # Capa de salida:\n",
    "    # - 1 neurona (clasificación binaria)\n",
    "    # - Activación sigmoide (probabilidad entre 0 y 1)\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Notas adicionales sobre la arquitectura:\n",
    "# 1. Progresión típica en CNNs: aumentar filtros mientras se reduce tamaño espacial\n",
    "# 2. BatchNorm después de convoluciones pero antes de activaciones (patrón común)\n",
    "# 3. Dropout aumenta progresivamente hacia las capas finales\n",
    "# 4. La arquitectura sigue el patrón: Conv -> BatchNorm -> Pooling -> Dropout\n",
    "# 5. Buena para imágenes pequeñas (100x100), podría profundizarse para imágenes más grandes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
